<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Applications of Machine Learning in Parkinson's Diagnosis</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Max Wang">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/maxwg.css" id="theme">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script>
    $( document ).ready(function() {
        $('sup').click(function(){
            var indices = Reveal.getIndices( document.getElementById( 'ref' ) );
            Reveal.slide( indices.h, indices.v );
        })
    });
    </script>
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
        $(document).ready(function(){
            $('section').each(function(sidx){
                var allrefs = new Set();
                $(this).find('sup').each(function(idx) {
                    var refs = this.innerText.split(",");
                    refs = refs.map(function (i) {
                        return parseInt(i)
                    })
                    for (var r in refs) {
                        allrefs.add(refs[r])
                    }
                });
                var lis = $("#references li")
                var text = "";
                allrefs.forEach(function(ref){
                    if (ref <= lis.length) {
                        var refli = lis[ref-1];
                        text += ref + ": " + refli.innerText + "<br/>"
                    } else{
                        console.log("REF ERROR: " + ref)
                    }
                });
                if(text != "") {
                    text = text.slice(0,-5);
                    $(this).append(
                        "<div class='citations'> <hr/>"
                        + text +
                        "</div>"
                    )
                }
                })

        });
            </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">

    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">
        <section class="full" data-background-image="img/pd2.png">
            <h1 style="margin-top:100px;">Applications of Machine Learning in Parkinson's Diagnosis</h1>
            <!--<h2 style="text-align:right">HONOURS 2017</h2>-->
            <img data-src="img/anu_logo.png" class="top-left" style="width:240px;">
            <p class="bottom-left">
                Max Wang <br style="display:block; margin-top:100px"/><span style="position:relative; top:-0.2em"><small
                    style="margin-top:0.3em"><a
                    href="mailto:u5584091@anu.edu.au">&lt;u5584091@anu.edu.au&gt;</a></small></span>
            </p>
            <br/>
            <blockquote style="width:100%; background-color:rgba(0,0,0,0.25); height:93px; padding:0;">
            <p style="float:right;margin-top:4px; margin-right:24px;">View Online:      <a href="https://maxwg.github.io/presentation">maxwg.github.io/presentation</a></p>
            <p style="float:right; margin-top:-24px; margin-right:24px;">Check For Parkinson's: &nbsp;<a href="https://maxwg.github.io/diagnosePD" target="_blank">maxwg.github.io/diagnosePD</a></p>
            </blockquote>
                <p style="text-align:right; position:absolute; bottom:0.4em; right:0;">
                <span style=" font-size:0.8em; line-height:0.8em">
                Supervised by: <br/>
                Dr Deborah Apthorp (ANU CBME &amp; CECS) <br/>
                Dr Hanna Suominen (ANU CECS &amp; DATA61)
                </span>
            </p>
        </section>
        <section>
            <blockquote style="padding: 20px 0 14px 0">
                Parkinson’s Disease (PD) is a degenerative neurological disorder that affects an estimated 53 million people
                worldwide<sup>&nbsp;1, 2</sup>
            </blockquote>
        </section>
        <section class="full">
            <blockquote style="top:200px">
                <div style="text-align:left; display:inline-block; width:92%; padding:20px 25px 10px 20px; font-family:'Fira Sans'; font-weight:500">
                <span style="display:block; color: #17C; font-style:italic">&ldquo;FOR PATIENTS, PARKINSON'S DISEASE <br/>&nbsp;IS NOT A TIME-NEUTRAL SITUATION, <br/>&nbsp;IT'S A TICKING CLOCK&rdquo;
                </span>
                    <span style="float:right; position:relative; top:-0.4em; color:#C32">- MICHAEL J. FOX</span>
                </div>
            </blockquote>
            <img src="img/mjfox.png" style="height:263px" class="bottom-right">

                <!--<img data-src="img/mjfox.png" style="float:right; width:30%">-->
        </section>

        <section>
            <h2>Symptoms</h2>
            <table style="font-size:0.8em" style="vertical-align:top">
                <tr>
                    <th>Motion</th><th>Speech</th><th>Non-Motor</th>
                </tr>
                <tr>
                    <td>
                        <ul>
                            <li>Resting Tremor</li>
                            <li>Rigidity</li>
                            <li>Akinesia <br/>(Freezing of Gait)</li>
                            <li>Bradykinesia<br/>
                            (Slow Movement)</li>
                            <li>Dyskinesia<br/>
                            (Difficulty of Movement)</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Dysphonia<br/>
                                (Breathy, Hoarse voice)</li>
                            <li>Reduced Volume</li>
                            <li>Monotonous Speech</li>
                            <li>Imprecise Articulation</li>
                            <li>Slurred Speech</li>
                            <li>Hesitant Speech</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Hallucinations</li>
                            <li>Reduced Cognitive Ability</li>
                            <li>Sleep Disorders</li>
                            <li>Mood Disorders</li>
                            <li>Vision Problems</li>
                            <li>Physical Changes</li>
                        </ul>
                    </td>
                </tr>
            </table>
        </section>
        <section>
            <h2 style="color:#333">Symptoms</h2>
            <table style="color:#333; font-size:0.8em" style="vertical-align:top">
                <tr>
                    <th>Motion</th><th>Speech</th><th>Non-Motor</th>
                </tr>
                <tr>
                    <td>
                        <ul>
                            <li>Resting Tremor</li>
                            <li>Rigidity</li>
                            <li>Akinesia <br/>(Freezing of Gait)</li>
                            <li>Bradykinesia<br/>
                            (Slow Movement)</li>
                            <li>Dyskinesia<br/>
                            (Difficulty of Movement)</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Dysphonia<br/>
                                (Breathy, Hoarse voice)</li>
                            <li>Reduced Volume</li>
                            <li>Monotonous Speech</li>
                            <li>Imprecise Articulation</li>
                            <li>Slurred Speech</li>
                            <li>Hesitant Speech</li>
                        </ul>
                    </td>
                    <td>
                        <ul>
                            <li>Hallucinations</li>
                            <li>Reduced Cognitive Ability</li>
                            <li>Sleep Disorders</li>
                            <li>Mood Disorders</li>
                            <li>Vision Problems</li>
                            <li>Physical Changes</li>
                        </ul>
                    </td>
                </tr>
            </table>
            <blockquote style="position:fixed; top:280px; left:150px; background-color:#333">Most PD patients suffer from a subset of these symptoms</blockquote>
        </section>
        <section>
            <p>
                <large>Parkinson's Disease is currently diagnosed with a subjective test by a trained neurologist.</large>
            </p>
            <ul>
                <li class="fragment">Misdiagnosis rates are high. Studies range from 9-34&#37;<sup>3,4,5,6</sup></li>
                <li class="fragment">Diagnosis is difficult in early stages of the disease as symptoms have not fully
                    manifested<sup>&nbsp;3</sup></li>
                <li class="fragment">There are a number of diseases with similar symptoms: <sup>&nbsp;7</sup>
                    <ul>
                        <li>Essential Tremor</li>
                        <li>Dystonia</li>
                        <li>Multiple Systems Atrophy</li>
                        <li>Supranuclear Palsy</li>
                        <li>Huntingtons Disease and more</li>
                    </ul>
                </li>
            </ul>
        </section>
        <section data-background-iframe="micvis.html">
            <large><p style="font-weight:100 !important;">What can I help you with?</p></large>
            <p class="fragment" style="font-weight:100">
                <audio data-autoplay src="img/siri.mp3"></audio>Say "aaaaah" into the microphone</p>
            <img class="fragment" data-src="img/loading.gif" style="width:50px;"/>
        </section>
        <section>
            <large><p style="font-weight:100">What can I help you with?</p></large>
            <p style="font-weight:100">Say "aaaaah" into the microphone</p>
            <p style="margin-bottom:54px; font-size:0.9em"><audio data-autoplay src="img/siri2.wav"></audio> It is highly unlikely you have Parkinson's Disease.</p>

        </section>
        <section data-transition-speed="slow" data-transition="concave" data-background-transition="concave" data-background-image="img/nicebg2.png">
            <h1>Prior Work</h1>
        </section>
        <!--<section class="full">-->
            <!--<iframe class="full" data-src="https://maxwg.github.io/projects/honours/presentation/scrolling_bib.html">-->
            <!--</iframe>-->
        <!--</section>-->

        <section>
<h3>Diagnosis</h3>
            <ul>
                <li>Current results are promising, with many papers reporting greater than 90% classification accuracy.
                <ul class="fragment">
                    <li>The basis of these results seem to be flawed. All current datasets consist of (often late stage) patients already diagnosed with PD vs control</li>
                </ul></li>
                <li class="fragment">Without a standardised longitudinal dataset, results from Machine Leaning models are meaningless</li>
                <li class="fragment">The fundamental question: <blockquote style="padding:7px 30px 7px 30px;"><i>Can Machine Learning diagnose PD better than a trained neurologist?</i></blockquote>
                </li>
            </ul>
        </section>
        <section>
            <blockquote style="padding:10px"><i>Can Machine Learning diagnose PD better than a trained neurologist?</i></blockquote>
            <p>
               Let's select PD patients with no identifiable motor impairment based on their UPDRS scores and check if a Machine Learning model can obtain statistically significant results.
            </p>
        </section>
        <section class="full">
            <large><p>Current models are based on a single measurable symptom</p></large>
            <table style="font-size:0.8em" style="vertical-align:top; ">
                <tr>
                    <th>Motion</th><th>Speech</th><th>Non-Motor</th>
                </tr>
                <tr>
                    <td style="width:34%">
                        <ul>
                            <li>Resting Tremor</li>
                            <li>Rigidity</li>
                            <li>Akinesia <br/>(Freezing of Gait)</li>
                            <li>Bradykinesia<br/>
                                (Slow Movement)</li>
                            <li>Dyskinesia<br/>
                                (Difficulty of Movement)</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        <ul>
                            <li>Dysphonia<br/>
                                (Breathy, Hoarse voice)</li>
                            <li>Reduced Volume</li>
                            <li>Monotonous Speech</li>
                            <li>Imprecise Articulation</li>
                            <li>Slurred Speech</li>
                            <li>Hesitant Speech</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        <ul>
                            <li>Hallucinations</li>
                            <li>Reduced Cognitive Ability</li>
                            <li>Sleep Disorders</li>
                            <li>Mood Disorders</li>
                            <li>Vision Problems</li>
                            <li>Physical Changes</li>
                        </ul>
                    </td>
                </tr>
            </table>
        </section>
        <section class="full">
            <large><p>Current models are based on a single measurable symptom</p></large>
            <table style="font-size:0.8em" style="vertical-align:top; ">
                <tr>
                    <th>Motion</th>
                    <th>Speech</th>
                    <th>Non-Motor</th>
                </tr>
                <tr>
                    <td style="width:34%">
                        <ul>
                            <li>Resting Tremor
                            <ul>
                                <li>Accelerometers<sup>&nbsp;9,10,11</sup></li>
                                <li>Smartphones<sup>&nbsp;12,13,14</sup></li>
                            </ul>
                            </li>
                            <li>Postural Sway
                            <ul>
                                <li>Force Plates<sup>&nbsp;15</sup></li>
                            </ul></li>
                            <li>Gait
                            <ul>
                            <li>Force Walkways<sup>&nbsp;16,17,18</sup></li>
                            <li>Video<sup>&nbsp;17</sup></li>
                            <li>Multiple IMUs<sup>&nbsp;19,20,21</sup></li>
                            </li>
                            </ul>
                            <li>Handwriting<sup>&nbsp;22,23</sup></li>

                        </ul>
                    </td>
                    <td style="width:33%">
                        <ul>
                            <li>English/German sentences<sup>&nbsp;24</sup></li>
                            <li class="fragment highlight-red" data-fragment-index="1">Prolonged vowel pronunciations<sup>&nbsp;25,26,27</sup></li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        <ul>
                            <li class="fragment highlight-red" data-fragment-index="1">Demographic Data</li>
                            <li>UPDRS Patient Questionnaire<sup>&nbsp;30,34</sup></li>
                            <li>Physical Changes
                            <ul>
                                <li>Gene Expression<sup>&nbsp;28,29</sup></li>
                                <li>MRIs<sup>&nbsp;31,32,33</sup></li>
                                <li>Olfactory<sup>&nbsp;34</sup></li>
                                <li>REM sleep<sup>&nbsp;30,34</sup></li>
                                <li>Cerebrospinal Fluids<sup>&nbsp;34</sup></li>
                                <li>Gastrointestinal<sup>&nbsp;35</sup></li>
                            </ul>
                            </li>
                        </ul>
                    </td>
                </tr>
            </table>
        </section>
        <section class="full">
            <large style="color:#333"><p>Current models are based on a single measurable symptom</p></large>
            <table style="font-size:0.8em" style="vertical-align:top;">
                <tr>
                    <th style=" color:#333">Motion</th>
                    <th style="color:#333">Speech</th>
                    <th style=" color:#333">Non-Motor</th>
                </tr>
                <tr>
                    <td style="color:#333; width:34%">
                        <ul>
                            <li>Resting Tremor
                                <ul>
                                    <li>Accelerometers<sup style="color:#0d3349">&nbsp;9,10,11</sup></li>
                                    <li>Smartphones<sup style="color:#0d3349">&nbsp;12,13,14</sup></li>
                                </ul>
                            </li>
                            <li>Postural Sway
                                <ul>
                                    <li>Force Plates<sup style="color:#0d3349">&nbsp;15</sup></li>
                                </ul></li>
                            <li>Gait
                                <ul>
                                    <li>Force Walkways<sup style="color:#0d3349">&nbsp;16,17,18</sup></li>
                                    <li>Video<sup style="color:#0d3349">&nbsp;17</sup></li>
                                    <li>Multiple IMUs<sup style="color:#0d3349">&nbsp;19,20,21</sup></li>
                                    </li>
                                </ul>
                            <li>Handwriting<sup style="color:#0d3349">&nbsp;22,23</sup></li>

                        </ul>
                    </td>
                    <td style="width:33%; color:#333">
                        <ul>
                            <li>English/German sentences<sup style="color:#0d3349">&nbsp;24</sup></li>
                            <li style="color:#422; ">Prolonged vowel pronunciations<sup style="color:#0d3349">&nbsp;25,26,27</sup></li>
                        </ul>
                    </td>
                    <td style="width:33%;  color:#333">
                        <ul>
                            <li style="color:#422">Demographic Data</li>
                            <li>UPDRS Patient Questionnaire<sup style="color:#0d3349">&nbsp;30,34</sup></li>
                            <li>Physical Changes
                                <ul>
                                    <li>Gene Expression<sup style="color:#0d3349">&nbsp;28,29</sup></li>
                                    <li>MRIs<sup style="color:#0d3349">&nbsp;31,32,33</sup></li>
                                    <li>Olfactory<sup style="color:#0d3349">&nbsp;34</sup></li>
                                    <li>REM sleep<sup style="color:#0d3349">&nbsp;30,34</sup></li>
                                    <li>Cerebrospinal Fluids<sup style="color:#0d3349">&nbsp;34</sup></li>
                                    <li>Gastrointestinal<sup style="color:#0d3349">&nbsp;35</sup></li>
                                </ul>
                            </li>
                        </ul>
                    </td>
                </tr>
            </table>
            <blockquote style="position:fixed; top:240px; width:700px; left:100px; background-color:#333; padding:10px">
                <ul>
                    <li>Easy to record</li>
                    <li>Speech signal processing is more advanced than other domains</li>
                </ul>
            </blockquote>
        </section>
        <section data-transition-speed="slow" data-transition="concave" data-background-transition="concave"
                 data-background-iframe="https://maxwg.github.io/spectrogram/index.html">
            <h1>Speech</h1>
            <p>(The Fourier Domain)</p>
        </section>
        <section data-background-color="#fff" data-transition-speed="fast">
            <h2 style="color:#555">Machine learning classification</h2>
            <img src="img/classification.png" style="width:600px"/>
        </section>

        <section>
            <p style="font-size:0.95em">
                <large style="font-size:1.15em">Current state of the art dysphonia classification involves:</large>
            </p>
            <ol style="width:90%">
                <li><i>Signal Processing</i> : Extracting relevant features from voice recordings </li>
                <li class="fragment"><i>Feature Selection/Dimensionality Reduction</i> : Eliminating redundant features and combining features</li>
                <li class="fragment"><i>Model Fitting</i> : Training and evaluating a machine learning algorithm</li>
            </ol>
        </section>
        <section>
            <p style="font-size:0.95em">
                <large style="font-size:1.15em">Current state of the art dysphonia classification involves:</large>
            </p>
            <ol style="width:90%">
                <li><i>Signal Processing</i> : Extracting relevant features from voice recordings </li>
                <li><i>Feature Selection/Dimensionality Reduction</i> : Eliminating redundant features and combining features</li>
                <li style="color:#ff2c2d"><i>Model Fitting</i> : Training and evaluating a machine learning algorithm</li>
            </ol>
        </section>
        <section>
            <p style="font-size:0.95em">
                <large style="font-size:1.15em">Current state of the art dysphonia classification involves:</large>
            </p>
            <ol style="width:90%">
                <li style="color:#ff2c2d"><i>Signal Processing</i> : Extracting relevant features from voice recordings </li>
                <li style="color:#ff2c2d"><i>Feature Selection/Dimensionality Reduction</i> : Eliminating redundant features and combining features</li>
                <li><i>Model Fitting</i> : Training and evaluating a machine learning algorithm</li>
            </ol>
        </section>
        <section>
            <h3>Current Datasets</h3>
            <ul>
                <li>Current research is primarily based on two public datasets:
                    <ul>
                        <li>Little&nbsp;et&nbsp;al.&nbsp;(2009)<sup>26</sup> 23 PD and 8 control; pre-processed features</li>
                        <li>Sankar&nbsp;et&nbsp;al.&nbsp;(2013)<sup>27</sup> 20 PD and 20 control; raw recordings </li></ul></li>
                <li class="fragment">The small size of both datasets limits the usefulness of feature evaluation</li>
                <li class="fragment">There is a disproportionate amount of PD vs control</li>
                <li class="fragment">All patients in both datasets exhibit speech difficulties</li>
            </ul>
        </section>
        <section>
            <h1>The mPower Dataset<sup>&nbsp;36</sup></h1>
        </section>
        <section data-background-color="#fff">
            <img data-src="img/mpower.png" style="width:100%"/>
        </section>
        <section data-background-color="#191919" data-transition="fast">
            <img data-src="img/mpower2.png" style="width:100%"/>
            <blockquote style="position:fixed; top:300px; left:150px;">
                65,000 speech recordings from 6,000 patients, ~1,200 with Parkinson's Disease
            </blockquote>
        </section>
        <section data-background-color="#191919" data-transition="fast">
            <img data-src="img/mpower2.png" style="width:100%"/>
            <blockquote style="position:fixed; top:280px; left:150px;">
                Patients come for a variety of backgrounds and races and may suffer from other conditions. Some have early-onset PD.
            </blockquote>
        </section>
        <section data-background-color="#191919" data-transition="fast">
            <img data-src="img/mpower2.png" style="width:100%"/>
            <blockquote style="position:fixed; top:230px; left:60px; width:800px;">
                After filtering and selecting the best audio files, 4,100 patients remained, 900 with PD.
                <br/>
                <br/> 81 (of 160) patients without speech symptoms selected based on UPDRS survey and self-listening.
                <br/>
            </blockquote>

        </section>
        <section>
            <large><p>Data is 'noisy' and may not be accurate.</p></large>
            <ul>
                <li class="fragment">~600 files were hand labelled from 1s excerpts, and hand tweaked criteria used to loosely filter and rank audio files </li>
                <li class="fragment">Resource limitation: We only considered the best recordings for each patient</li>
            </ul>
        </section>

        <section>
            <p style="font-size:0.95em">
                <large style="font-size:1.15em">Current state of the art dysphonia classification involves:</large>
            </p>
            <ol style="width:90%">
                <li><i>Signal Processing</i> : Extracting relevant features from voice recordings </li>
                <li style="color:#ff2c2d"><i>Feature Selection/Dimensionality Reduction</i> : Eliminating redundant features and combining features (optional)</li>
                <li style="color:#ff2c2d"><i>Model Fitting</i> : Training and evaluating a machine learning algorithm</li>
            </ol>
        </section>

        <section data-background-color="#FFFFFF" style="color:#333 !important">
            <large style="float:left; margin-top:130px;width:360px; text-align: right">Results of Tsanas&nbsp;et&nbsp;al.<sup>&nbsp;39</sup> <small>
                <br/>10 Controls <br/>(4M/6F; age &mu;=61, &sigma;= 8.6)<br/><br/>
                33 PD <br/>(22M/11F age &mu;=67.2, &sigma;= 9.3).<br/><br/>
                Diagnosed &mu;=5.8 &sigma;=6.3 years ago</small></large>
            <img data-src="img/Tsanas.png" style="height:640px; margin-right:40px; float:right;"/>
        </section>

        <section data-background-color="#fff">
            <h2 style="color:#555">The (linear) SVM</h2>
            <img src="img/svm.gif" >
        </section>

        <section class="full" style="color:#333 !important" data-background-color="#fff" >
            <br/>
            <h3 style="color:#555">Tsanas relieff results on mPower</h3>
            <p>Best accuracy from SVM gridsearch (10 fold 10 repetiton CV)</p>
            <table style="font-size: 0.8em">
                <tr>
                    <td style="text-align: center"><large>33PD/10C <br/>(Tsanas NCVS) split</large>
                    <table>
                        <tr>
                            <td></td>
                            <td>Pred PD</td>
                            <td>Pred C</td>
                        </tr>
                        <tr>
                            <td>Real PD</td>
                            <td>204</td>
                            <td>0</td>
                        </tr>
                        <tr>
                            <td>Real C</td>
                            <td>62</td>
                            <td>0</td>
                        </tr>
                    </table>
                    <table style="float:left; font-size:0.8em">
                        <tr>
                            <td>Accuracy:</td>
                            <td>76.7%</td>
                        </tr>
                        <tr>
                            <td>Sensitivity (TP):</td>
                            <td>100%</td>
                        </tr>
                        <tr>
                            <td>Specificity (TN):</td>
                            <td>0%</td>
                        </tr>
                    </table>
                    </td>
                    <td style="text-align: center"><large>50PD/50C equal split</large>
                    <table>
                        <tr>
                            <td></td>
                            <td>Pred PD</td>
                            <td>Pred C</td>
                        </tr>
                        <tr>
                            <td>Real PD</td>
                            <td>113.4</td>
                            <td>91.0</td>
                        </tr>
                        <tr>
                            <td>Real C</td>
                            <td>64.0</td>
                            <td>140.6</td>
                        </tr>
                    </table>
                    <table style="float:left; font-size:0.8em">
                        <tr>
                            <td>Accuracy:</td>
                            <td>62.1%</td>
                        </tr>
                        <tr>
                            <td>Sensitivity (TP):</td>
                            <td>55.48%</td>
                        </tr>
                        <tr>
                            <td>Specificity (TN):</td>
                            <td>68.7%</td>
                        </tr>
                    </table>
                    </td>
                    <td style="text-align: center; vertical-align: middle !important;"><large>10PD/39C (mPower) split</large>
                    <table>
                        <tr>
                            <td></td>
                            <td>Pred PD</td>
                            <td>Pred C</td>
                        </tr>
                        <tr>
                            <td>Real PD</td>
                            <td>2.4</td>
                            <td>202.0</td>
                        </tr>
                        <tr>
                            <td>Real <br/>C</td>
                            <td>0.8</td>
                            <td>774.7</td>
                        </tr>
                    </table>
                    <table style="float:left; font-size:0.8em">
                        <tr>
                            <td>Accuracy:</td>
                            <td>79.3%</td>
                        </tr>
                        <tr>
                            <td>Sensitivity (TP):</td>
                            <td>0.012%</td>
                        </tr>
                        <tr>
                            <td>Specificity (TN):</td>
                            <td>99.9%</td>
                        </tr>
                    </table>
                    </td>
                </tr>
            </table>
        </section>


        <section data-background-color="#FFFFFF" style="color:#333 !important">
            <ul style="float:left; margin-top:230px;width:300px; text-align: right">
                <large>Possible Causes</large><br/>
                <li>Higher Quality Data</li>
                <li>Cross-val Overfitting</li>
            </ul>
            <img data-src="img/Tsanas.png" style="height:640px; margin-right:40px; float:right;"/>
        </section>

        <section>
            <large> <p>&ldquo;A ML model is only as good as its features.&rdquo;</p></large>
            <ul>
                <!--<li>Speakers with dysphonia often deviate from the simplified linear source-filter speech model<sup>&nbsp;38</sup></li>-->
                <li>Dysphonia quantification features are based on finding the fundamental frequency (glottal cycles per second)<sup>&nbsp;37,&nbsp;38</sup>
                    <ul>
                        <li>
                            Finding the fundamental frequency is a research field in itself
                        </li>
                    </ul>
                </li>
                <li class="fragment">A variety of other features exist in the field of speech language/emotion classification<sup>&nbsp;40</sup></li>
                <li class="fragment">We combine the 338 SOTA dysphonia measurements in Tsanas&nbsp;et&nbsp;al.<sup>&nbsp;39</sup> with 67 additional features in the eGeneva acoustic feature set<sup>&nbsp;41, 42</sup>, age, gender, race(one-hot) and phone.</li>
            </ul>
        </section>
        <section class="full">
            <br/>
            <table style="font-size:0.9em">
                <h3>Supervised Feature Selection Methods<sup>&nbsp;43</sup></h3>
                <tr><th>Filters</th><th>Wrappers</th><th>Embedded Methods</th></tr>
                <tr style="font-size:0.9em">
                    <td style="width:34%">
                        Evaluate subsets of features by maximising various criteria such as entropy, similarity or statistical measures.
                        <ul>
                            <li>Fast evaluation of subsets</li>
                            <li>Model independent results</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        &ldquo;Wrap&rdquo; around existing ML models, evaluating feature subsets with the model's cross validation score
                        <ul>
                            <li>More expensive to evaluate subsets</li>
                            <li>Results are better tailored to wrapped models</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        Machine Learning Models which perform feature selection as part of the training process
                        <ul>
                            <li>Highly model specific.</li>
                            <li>Greatly reduces model 'complexity'</li>
                        </ul>
                    </td>
                </tr>
            </table>
        </section>
        <section class="full" style="color:#333 !important">
            <br/>
            <table style="font-size:0.9em">
                <h3 style="color:#333">Supervised Feature Selection Methods<sup style="color:#0d3349">&nbsp;43</sup></h3>
                <tr><th>Filters</th><th>Wrappers</th><th>Embedded Methods</th></tr>
                <tr style="font-size:0.9em">
                    <td style="width:34%">
                        Evaluate subsets of features by maximising various criteria such as entropy, similarity or statistical measures.
                        <ul>
                            <li>Fast evaluation of subsets</li>
                            <li>Model independent results</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        &ldquo;Wrap&rdquo; around existing ML models, evaluating feature subsets with the model's cross validation score
                        <ul>
                            <li>More expensive to evaluate subsets</li>
                            <li>Results are better tailored to wrapped models</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                        Machine Learning Models which perform feature selection as part of the training process
                        <ul>
                            <li>Highly model specific.</li>
                            <li>Greatly reduces model 'complexity'</li>
                            <li>Generally more parameters to optimize over</li>
                        </ul>
                    </td>
                </tr>
            </table>
            <blockquote style="position:fixed; top:280px; left:150px; background-color:#333; color:#EEE">
                Feature Selection is highly dependent on dataset size and type.
            </blockquote>
        </section>
        <section class="full">
            <br/>
            <table style="font-size:0.9em">
                <h3>Supervised Feature Selection Methods<sup>&nbsp;43</sup></h3>
                <tr><th>Filters</th><th>Wrappers</th><th>Embedded Methods</th></tr>
                <tr style="font-size:0.9em">
                    <td style="width:34%">
                        <ul>
                            <li>reliefF</li>
                            <li>Fisher Score</li>
                            <li>MIFS</li>
                            <li>CIFE</li>
                            <li>JMI</li>
                            <li>MRMR</li>
                            <li>ICAP</li>
                        </ul>
                    </td>
                    <td style="width:33%">
                    <ul>
                        <li>Forwards Feature Search
                        </li>
                        <li>Backwards Feature Elimination</li>
                    </ul>
                    </td>
                    <td style="width:33%">
                    <ul>
                        <li>RFS</li>
                        <li>ls_l21</li>
                    </ul>
                    </td>
                </tr>
            </table>
        </section>
        <section data-background-color="#FFFFFF" style="color:#333 !important">
            <img data-src="img/svmfs1.png" />
        </section>

        <section data-background-color="#FFFFFF" style="color:#333 !important">
            <img data-src="img/svmfs2.png"/>
        </section>

        <section data-background-color="#FFFFFF" style="color:#333 !important">
            <img data-src="img/svmfsdemo.png"/>
        </section>
        <section data-background-color="#fff">
            <img data-src="img/mpowerage.png" style="width:100%"/>
            <p style="color:#333">Age is an immensely powerful predictor with mPower -- predicting PD ⇔ age &ge; 52 has a 86.1% accuracy </p>
        </section>

        <section>
            <large><p>We clearly need to change approaches...</p></large>
            <p>Although traditional linear ML techniques may work for the small, clean datasets used in previous works,  mPower is noisy and large.</p>
        </section>

        <section>
            <large>Most features are barely separable</large>
            <img data-src="img/tkeo.png"/>
        </section>
        <section>
            <large>F<sub style="font-size:0.7em">0</sub> Estimation algorithms perform questionably</large>
            <img data-src="img/PPE.png"/>
        </section>
        <section>
            <h2>Non-linearities in speech features</h2>
            <ul>
                <li>How does age, race or gender affect speech?</li>
                <li class="fragment">What information do discreptencies between F<sub style="font-size:0.7em">0</sub> based and
                spectral/cepstral based provide? </li>
                <li class="fragment">How do the different microphones in each iPhone model affect recordings?</li>
            </ul>
        </section>
        <section data-background-color="#fff" class="full">
            <br/>
            <h2 style="color:#555">The (linear) SVM</h2>
            <img src="img/svm.gif" >
        </section>

        <section data-background-color="#fff" class="full">
            <br/>
            <h2 style="color:#555">The (linear) SVM</h2>
            <large style="color:#555"><p>Kernels can transform nonlinear data</p></large>
            <img src="img/basisfn.png" >
        </section>

        <section data-background-color="#fff">
            <h2 style="color:#555">(Deep) Neural Networks</h2>
            <img src="img/nnet.jpeg" >
        </section>

        <section data-background-color="#fff" class="full">
            <h3 style="color:#555">Classifying Nonlinear Functions (xor ⊕)</h3>
            <img src="img/nnetcomparison.png" style="height:600px;" >
        </section>
        <section>
            <h3>Neural Network Parameters</h3>
            <span style="font-size:0.75em"><ul>
                <li>Number/type of Layers?</li>
                <li>Number of nodes in each layer?</li>
                <li>Activation Functions? {ReLU, sigmoid, tanh, identity, ...}</li>
                <li>Loss Function? {MSE, MAE, Tweedie based, KL divergence, cross-entropy, ...}</li>
                <li>Regularization? {L1, L2, dropout, ...} </li>
                <li>Weight Initialization? {Glorot/Xavier, He, Lecun, random, autoencoder...} </li>
                <li>Optimizer? {SGD, RMS, Ada, Adam, NAdam, ....}</li>
                <li>Optimizer Parameters? {Learning Rate, momentum, training epochs, batch size, ...}</li>
            </ul></span>
        </section>
        <section>
            <h3>The Dangers of neural networks: Overfitting</h3>
            <ul>
                <li>Even with cross validation, overfitting occurs from model selection due to the number of free parameters </li>
                <li>A separate test set was used along with cross validation. </li>
                <li>All feature selection and normalization was done with respect to the training data</li>
                <li>Trained neural networks were highly regularized, checking for stable and converged training and CV results</li>
            </ul>
        </section>

        <section>
            <h3>Model Selection</h3>
            <ul>
                <li>Intuition combined with large neigbourhood search was used to find good parameters for the model
                    <br/><small style="margin-left:150px;">(Search was implemented with hyperopt, which relies on a Tree of Parzen Estimators<sup>&nbsp;44</sup>)</small></li>
                <li class="fragment">The final network has 9 hidden layers with ReLU activations.
                    <ul>
                        <li>L1 regularization on the first three layers to prevent overfitting</li>
                        <li>Nodes were initialised with the He<sup>&nbsp;45</sup> normal method and NAdam<sup>&nbsp;47</sup> used as the optimizer. The network was implemented with Keras<sup>&nbsp;46</sup></li>
                    </ul>
                    <img src="img/model.png">
                </li>
            </ul>
        </section>

        <section data-background-image="img/nicebg1.jpg" data-background-transition="concave" data-transition="concave" data-transition-speed="slow">
            <h1>Results</h1>
        </section>
        <section class="full">
            <br/>
            <large><p>Naive predictions on all features</p></large>
            <table style="font-size: 0.8em">
                <tr>
                    <td style="text-align: center"><large>Cross-Val</large>
                        <table>
                            <tr>
                                <td></td>
                                <td>Pred PD</td>
                                <td>Pred C</td>
                            </tr>
                            <tr>
                                <td>Real PD</td>
                                <td>585</td>
                                <td>196</td>
                            </tr>
                            <tr>
                                <td>Real C</td>
                                <td>183</td>
                                <td>2949</td>
                            </tr>
                        </table>
                        <table style="float:left; font-size:0.8em">
                            <tr>
                                <td>Accuracy:</td>
                                <td>90.3%</td>
                            </tr>
                            <tr>
                                <td>Sensitivity (TP):</td>
                                <td>74.9%</td>
                            </tr>
                            <tr>
                                <td>Specificity (TN):</td>
                                <td>94.2%</td>
                            </tr>
                            <tr>
                                <td>Area Under ROC:</td>
                                <td>93.0%</td>
                            </tr>
                        </table>
                    </td>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td style="text-align: center"><large>Test</large>
                        <table>
                            <tr>
                                <td></td>
                                <td>Pred PD</td>
                                <td>Pred C</td>
                            </tr>
                            <tr>
                                <td>Real PD</td>
                                <td>61</td>
                                <td>20</td>
                            </tr>
                            <tr>
                                <td>Real C</td>
                                <td>21</td>
                                <td>298</td>
                            </tr>
                        </table>
                        <table style="float:left; font-size:0.8em">
                            <tr>
                                <td>Accuracy:</td>
                                <td>89.8%</td>
                            </tr>
                            <tr>
                                <td>Sensitivity (TP):</td>
                                <td>75.3%</td>
                            </tr>
                            <tr>
                                <td>Specificity (TN):</td>
                                <td>93.4%</td>
                            </tr>
                            <tr>
                                <td>Area Under ROC:</td>
                                <td>92.2%</td>
                            </tr>
                        </table>
                    </td>

                </tr>
            </table>
            <p class="fragment" style="text-align:right;">Comparable to Little (2009)<sup>26</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[91.3% cross-val with 23PD/8C]<br/>
                Sakar (2012)<sup>27</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[75% cross-val with 20PD/20C]<br/>
                Hazan (2012)<sup>24</sup> [80% on 68PD/30C german speakers]  </p>

        </section>
        <section class="full">
            <br/>
            <large><p>Naive predictions on all features without gender demographics </p></large>
            <table style="font-size: 0.8em">
                <tr>
                    <td style="text-align: center"><large>Cross-Val</large>
                        <table>
                            <tr>
                                <td></td>
                                <td>Pred PD</td>
                                <td>Pred C</td>
                            </tr>
                            <tr>
                                <td>Real PD</td>
                                <td>276</td>
                                <td>505</td>
                            </tr>
                            <tr>
                                <td>Real C</td>
                                <td>95</td>
                                <td>3037</td>
                            </tr>
                        </table>
                        <table style="float:left; font-size:0.8em">
                            <tr>
                                <td>Accuracy:</td>
                                <td>84.7%</td>
                            </tr>
                            <tr>
                                <td>Sensitivity (TP):</td>
                                <td>35.3%</td>
                            </tr>
                            <tr>
                                <td>Specificity (TN):</td>
                                <td>97.0%</td>
                            </tr>
                            <tr>
                                <td>Area Under ROC:</td>
                                <td>84.6%</td>
                            </tr>
                        </table>
                    </td>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td></td>
                    <td style="text-align: center"><large>Test</large>
                        <table>
                            <tr>
                                <td></td>
                                <td>Pred PD</td>
                                <td>Pred C</td>
                            </tr>
                            <tr>
                                <td>Real PD</td>
                                <td>26</td>
                                <td>55</td>
                            </tr>
                            <tr>
                                <td>Real C</td>
                                <td>10</td>
                                <td>309</td>
                            </tr>
                        </table>
                        <table style="float:left; font-size:0.8em">
                            <tr>
                                <td>Accuracy:</td>
                                <td>83.8%</td>
                            </tr>
                            <tr>
                                <td>Sensitivity (TP):</td>
                                <td>32.0%</td>
                            </tr>
                            <tr>
                                <td>Specificity (TN):</td>
                                <td>96.9%</td>
                            </tr>
                            <tr>
                                <td>Area Under ROC:</td>
                                <td>79.8%</td>
                            </tr>
                        </table>
                    </td>

                </tr>
            </table>
            <p class="fragment">Almost 10% better than simpler models, but there's still a long way to go - especially with sensitivity!</p>
        </section>
        <section>
            <h3>Applying 'domain knowledge'</h3>
            <ul>
                <li>We know males and females have very different speech characteristics</li>
                <li class="fragment">But we do not have enough data to comfortably train two separate networks</li>
                <li class="fragment">Solution:
                <blockquote style="text-align: center">Transfer Learning<br/>
                </blockquote>
                <div style="text-align:center;">
                    <small>(This also applies to race however we have insufficient data.)</small>
                </div>
                </li>
            </ul>
        </section>
        <section>
                <blockquote style="text-align: center">Transfer Learning<br/>
                </blockquote>
            <p>We can initialize the weights of the network using the male participants, then train on the female participants and vice versa</p>
            <br/>
            <div class="fragment" style="text-align:left; margin-left:12px;">
                <large>Results</large><br/>
                <ul>
                    <li><i>All features:</i> Negligible difference</li>
                    <li><i>Voice features:</i><table style="font-size:0.7em; margin-left:220px;">
                        <tr>
                            <td>Test Accuracy</td>
                            <td>83.8%</td>
                            <td>→</td>
                            <td>85.0%</td>
                        </tr>
                        <tr>
                            <td>Test Specificity (TP)</td>
                            <td>32.0%</td>
                            <td>→</td>
                            <td>44.0%</td>
                        </tr>
                        <tr>
                            <td>Test Sensitivity (TN)</td>
                            <td>96.9%</td>
                            <td>→</td>
                            <td>95.9%</td>
                        </tr>
                        <tr>
                            <td>Area Under ROC</td>
                            <td>79.8%</td>
                            <td>→</td>
                            <td>81.2%</td>
                        </tr>
                    </table></li>
                </ul>
            </div>

        </section>
        <section style="color:#333 !important">
            <blockquote style="text-align: center; background-color:#252525;">Transfer Learning<br/>
            </blockquote>
            <p>We can initialize the weights of the network using the male participants, then train on the female participants and vice versa</p>
            <br/>
            <div style="text-align:left; margin-left:12px;">
                <large>Results</large><br/>
                <ul>
                    <li><i>All features:</i> Negligible difference</li>
                    <li><i>Voice features:</i><table style="font-size:0.7em; margin-left:220px;">
                        <tr>
                            <td>Test Accuracy</td>
                            <td>83.8%</td>
                            <td>→</td>
                            <td>85.0%</td>
                        </tr>
                        <tr>
                            <td>Test Specificity (TP)</td>
                            <td>32.0%</td>
                            <td>→</td>
                            <td>44.0%</td>
                        </tr>
                        <tr>
                            <td>Test Sensitivity (TN)</td>
                            <td>96.9%</td>
                            <td>→</td>
                            <td>95.9%</td>
                        </tr>
                        <tr>
                            <td>Area Under ROC</td>
                            <td>79.8%</td>
                            <td>→</td>
                            <td>81.2%</td>
                        </tr>
                    </table></li>
                </ul>
            </div>
            <blockquote style="position:fixed; top:217px; left:139px; background-color:#333; color:#EEE">
                What if we want better specificity?
            </blockquote>

        </section>
        <section>
            <blockquote>
                What if we want better specificity?
            </blockquote>
            <p>Change loss function/metrics</p>
            <p style="text-align:left">
            Reweighted binary-crossentropy to increase false-negative penalty;
                Used f-measure as metric</p>
        </section>
        <section>
            <blockquote style="position:fixed; top:217px; left:139px; background-color:#2d2d2d; color:#EEE">
                What if we want better specificity?
            </blockquote>
            <br/><br/><br/>
            <table>
                <tr>
                    <td>Test Accuracy</td>
                    <td>85.0%</td>
                    <td>→</td>
                    <td>82.0%</td>
                </tr>
                <tr>
                    <td>Test Specificity (TP)</td>
                    <td>44.0%</td>
                    <td>→</td>
                    <td>72.2%</td>
                </tr>
                <tr>
                    <td>Test Sensitivity (TN)</td>
                    <td>95.9%</td>
                    <td>→</td>
                    <td>84.8%</td>
                </tr>
                <tr>
                    <td>Area Under ROC</td>
                    <td>81.4%</td>
                    <td>→</td>
                    <td>82.7%</td>
                </tr>
            </table>
        </section>
        <section>
            <h2>Verifying Results</h2>
            <p>Sakar et al. (2012)<sup>27</sup> makes publicly available a dataset of vowel pronunciations from 28 PD patients without demographics data. </p>
            <ul class="fragment">
                <li>The voice feature trained model classifies <span style="color:#ff2c2d; font-weight:600;">23/28</span> correctly (82.1% specificity).</li>
            </ul>
        </section>
        <section>
            <p>Let's get back to the question at hand!</p>
            <blockquote style="padding:7px 30px 7px 30px;"><i>Can Machine Learning diagnose PD better than a trained neurologist?</i></blockquote>
            <ul class="fragment">
            <li>Trained on only voice features for all patients, 31 without speech conditions
                <ul><li>Predicted <span style="color:#ff2c2d; font-weight:600;">39/50</span> of the remaining without speech conditions correctly
                <span style="font-size:0.6em">(Note that higher quality data may also be a factor influencing the results)</span></li></ul></li>
                <li class="fragment"><i>The model appears to be looking for features very different from the typical human</i></li>
            </ul>
        </section>
        <section>
            <h2>Limitations and Shortcomings</h2>
            <ul>
                <li>The UPDRS questionnarie is filled out by users - responses may not reflect clinical diagnosis</li>
                <li>Computational limtations - optimally, data 'boosting' would be applied - using varying length excerpts of speech from each patient
                    <span style="font-size:0.6em">(I only had an i5 box with integrated graphics and barely enough RAM to kick up a DNN.)</span></li>
            </ul>
        </section>
        <section>
            <h2>Near Future Work</h2>
            <ol>
                <li>Developing a Machine Learning based filter for speech data with too much noise</li>
                <li>Work with the mPower accelerometer data to create a more accurate ensemble clasifier</li>
                <li>Explore classification with larger feature sets such as ComParE (15,000+ features)</li>

            </ol>
        </section>
        <section>
            <h2>Future Work <smaller style="vertical-align: middle"><sub>(in order of importance)</sub></smaller></h2>
            <ol>
                <li>Investigating the use of a time-series model such as a HMM or RNN to train and predict on short time features (e.g, glottal cycle length)</li>
                <li>Investigate the impacts of medication such as Levodopa </li>
                <li>Active Learning: Determine which patients to monitor</li>
                <li>Developing/modifying signal processing algorithms to suit non-linear dysphonia quantification</li>
            </ol>
        </section>
        <section class="scrollable" id="ref">
            <smaller>
                <h2>References</h2>
                <ol style="width:95%" id="references">
                    <large>Diagnosis</large>
                    <hr/>
                    <li>Tolosa, Eduardo, Gregor Wenning, and Werner Poewe. "The diagnosis of Parkinson's disease." The
                        Lancet Neurology 5.1 (2006): 75-86
                    </li>
                    <li>J. M. Savitt, V. L. Dawson, T. M. Dawson, Diagnosis and treatment of parkinson disease:
                        molecules to medicine, The Journal of clinical investigation 116 (2006) 1744–1754
                    </li>
                    <li>J. Jankovic, A. H. Rajput, M. P. McDermott, D. P. Perl, The evolution of diagnosis in early
                        parkinson disease, Archives of neurology 57 (2000) 369–372.
                    </li>
                    <li> D. J. Brooks, Parkinson’s disease: diagnosis, Parkinsonism & related disorders 18 (2012)
                        S31–S33.
                    </li>
                    <li>E. Tolosa, G. Wenning, W. Poewe, The diagnosis of parkinson’s disease, The Lancet Neurology 5
                        (2006) 75–86.
                    </li>
                    <li>A. J. Hughes, S. E. Daniel, L. Kilford, A. J. Lees, Accuracy of clinical diagnosis of idiopathic
                        parkinson’s disease: a clinico-pathological study
                    </li>
                    <li>S. Jain, S. E. Lo, E. D. Louis, Common misdiagnosis of a common neurological disorder: how are
                        we misdiagnosing essential tremor?, Archives of neurology 63 (2006) 1100–1104.
                    </li>
                    <li>C. G. Goetz, B. C. Tilley, S. R. Shaftman, G. T. Stebbins, S. Fahn, P. Martinez-Martin, W. Poewe, C. Sampaio, M. B. Stern, R. Dodel, et al., Movement disorder society-sponsored revision of the unified parkinson’s disease rating scale (mds-updrs): Scale presentation and clinimetric testing results, Movement disorders 23 (2008) 2129–2170</li>

                    <br/>
                    <large>Machine Learning</large>
                    <br/>
                    <br/>
                    Motion -> Tremor
                    <br/>
                    <hr/>
                    <!--motion-->
                    <!--tremor-->
                    <li>C. Duval, A. Sadikot, M. Panisset, The detection of tremor during slow alternating movements performed by patients with early parkinsons disease, Experimental brain research 154 (2004) 395–398.</li>
                    <li>A. Salarian, H. Russmann, C. Wider, P. R. Burkhard, F. J. Vingerhoets, K. Aminian, Quantification of tremor and bradykinesia in parkinson’s disease using a novel ambulatory monitoring system, IEEE Transactions on Biomedical Engineering 54 (2007) 313–322.</li>
                    <li>L. Palmerini, L. Rocchi, S. Mellone, F. Valzania, L. Chiari, Feature selection for accelerometer-based posture analysis in parkinson’s disease, IEEE Transactions on Information Technology in Biomedicine 15 (2011) 481–490.</li>
                   <br/>
                    Motion -> Tremor -> Smartphones
                    <hr/>
                    <!--Smartphone-->
                    <li>S. Arora, V. Venkataraman, S. Donohue, K. M. Biglan, E. R. Dorsey, M. A. Little, High accuracy discrimination of parkinson’s disease participants from healthy controls using smartphones, in: Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on, IEEE, pp. 3641–3644.</li>
                    <li>M. Brunato, R. Battiti, D. Pruitt, E. Sartori, Supervised and unsupervised machine learning for the detection, monitoring and management of parkinson’s disease from passive mobile phone data., Michael J Fox Foundation (2013).</li>
                    <li>C. Boussios, J. Greenbaum, B. Ieong, F. Kokkotos, S. Kokkotos, M. Zalesak, The construction of a novel statistical algorithm to objectively diagnose parkinsons disease using smartphone data, Michael J Fox Foundation (2013).</li>

                    <!--sway-->
                    <br/>
                    Motion -> Sway
                    <hr/>
                    <li>L. Rocchi, L. Chiari, A. Cappello, F. B. Horak, Identification of distinct characteristics of postural sway in parkinson’s disease: a feature selection procedure based on principal component analysis, Neuroscience letters 394 (2006) 140–145.</li>
                    <br/>
                    Gait -> Walkway
                    <hr/>
                    <!--gait-->
                    <!--walkway-->
                    <li>R. Begg, J. Kamruzzaman, Neural networks for detection and classification of walking pattern changes due to ageing, Australasian Physical & Engineering Science in Medicine 29 (2006) 188–195.</li>
                    <li>R. d. M. Roiz, E. W. A. Cacho, M. M. Pazinatto, J. G. Reis, A. Cliquet Jr, E. Barasnevicius-Quagliato, Gait analysis comparing parkinson’s disease with healthy elderly subjects, Arquivos de neuropsiquiatria 68 (2010) 81–86.</li>
                    <li>A. Khorasani, M. R. Daliri, Hmm for classification of parkinson’s disease based on the raw gait data, Journal of medical systems 38 (2014) 1</li>
                    <br/>
                    Gait -> IMUs
                    <hr/>
                    <!--IMU-->
                    <li>J. Barth, J. Klucken, P. Kugler, T. Kammerer, R. Steidl, J. Winkler, J. Hornegger, B. Eskofier, Biometric and mobile gait analysis for early diagnosis and therapy monitoring in parkinson’s disease, in: Engineering in Medicine and Biology Society, EMBC, 2011 Annual International Conference of the IEEE, IEEE, pp. 868–871.</li>
                    <li>V. Renaudin, M. Susi, G. Lachapelle, Step length estimation using handheld inertial sensors, Sensors 12 (2012) 8507–8525.</li>
                    <li>B. Sijobert, M. Benoussaad, J. Denys, R. Pissard-Gibollet, C. Geny, C. A. Coste, Implementation and validation of a stride length estimation algorithm, using a single basic inertial sensor on healthy subjects and patients suffering from parkinson’s disease, ElectronicHealthcare (2015) 704–714.</li>
                    <br/>
                    Handwriting
                    <hr/>
                    <li>P. Drot´ar, J. Mekyska, I. Rektorov´a, L. Masarov´a, Z. Sm´ekal, M. Faundez-Zanuy, Decision support framework for parkinsons disease based on novel handwriting markers, IEEE Transactions on Neural Systems and Rehabilitation Engineering 23 (2015) 508–516.</li>
                    <li>C. Kotsavasiloglou, N. Kostikis, D. Hristu-Varsakelis, M. Arnaoutoglou, Machine learning-based classification of simple drawing movements in parkinson’s disease, Biomedical Signal Processing and Control 31 (2017) 174–180.</li>

                    <br/>
                    Speech -> English/German
                    <hr/>
                    <li>H. Hazan, D. Hilu, L. Manevitz, L. O. Ramig, S. Sapir, Early diagnosis of parkinson’s disease via machine learning on speech data, in: Electrical 10 & Electronics Engineers in Israel (IEEEI), 2012 IEEE 27th Convention of, IEEE, pp. 1–4.</li>
                    <br/>
                    Speech -> Prolonged Vowed Pronunications
                    <hr/>
                    <li>L. Cnockaert, J. Schoentgen, P. Auzou, C. Ozsancak, L. Defebvre, F. Grenez, Low-frequency vocal modulations in vowels produced by parkinsonian subjects, Speech communication 50 (2008) 288–300</li>
                    <li>M. A. Little, P. E. McSharry, E. J. Hunter, J. Spielman, L. O. Ramig, et al., Suitability of dysphonia measurements for telemonitoring of parkinson’s disease, IEEE transactions on biomedical engineering 56 (2009) 1015–1022.</li>
                    <li>B. E. Sakar, M. E. Isenkul, C. O. Sakar, A. Sertbas, F. Gurgen, S. Delil, H. Apaydin, O. Kursun, Collection and analysis of a parkinson speech dataset with multiple types of sound recordings, IEEE Journal of Biomedical and Health Informatics 17 (2013) 828–834.</li>
                    <!--nonmotor-->
                    <br/>
                    Non-motor
                    <hr/>
                    <li>C. R. Scherzer, A. C. Eklund, L. J. Morse, Z. Liao, J. J. Locascio, D. Fefer, M. A. Schwarzschild, M. G. Schlossmacher, M. A. Hauser, J. M. Vance, et al., Molecular markers of early parkinson’s disease based on gene expression in blood, Proceedings of the National Academy of Sciences 104 (2007) 955–960.</li>
                    <li>G. S. Babu, S. Suresh, Parkinsons disease prediction using gene expression–a projection based learning meta-cognitive neural classifier approach, Expert Systems with Applications 40 (2013) 1519–1529.</li>
                    <li>R. Arma˜nanzas, C. Bielza, K. R. Chaudhuri, P. Martinez-Martin, P. Larra˜naga, Unveiling relevant non-motor parkinson’s disease severity symptoms using a machine learning approach, Artificial intelligence in medicine 58 (2013) 195–202.</li>
                    <li>C. Salvatore, A. Cerasa, I. Castiglioni, F. Gallivanone, A. Augimeri, M. Lopez, G. Arabia, M. Morelli, M. Gilardi, A. Quattrone, Machine learning on brain mri data for differential diagnosis of parkinson’s disease and progressive supranuclear palsy, Journal of Neuroscience Methods 222 (2014) 230–237.</li>
                    <li>D. A. Morales, Y. Vives-Gilabert, B. G´omez-Ans´on, E. Bengoetxea, P. Larra˜naga, C. Bielza, J. Pagonabarraga, J. Kulisevsky, I. CorcueraSolano, M. Delfino, Predicting dementia development in parkinson’s disease using bayesian network classifiers, Psychiatry Research: NeuroImaging 213 (2013) 92–98.</li>
                    <li>A. W. Przybyszewski, Applying data mining and machine learning algorithms to predict symptom development in parkinson’s disease, in: Annales Academiae Medicae Silesiensis, volume 68, pp. 332–349.</li>
                    <li>K. N. R. Challa, V. S. Pagolu, G. Panda, B. Majhi, An improved
                    approach for prediction of parkinson’s disease using machine learning
                        techniques, arXiv preprint arXiv:1610.08250 (2016).</li>
                    <li>M. G. Cersosimo, G. B. Raina, C. Pecci, A. Pellene, C. R. Calandra,
                    C. Guti´errez, F. E. Micheli, E. E. Benarroch, Gastrointestinal manifestations
                    in parkinsons disease: prevalence and occurrence before motor
                        symptoms, Journal of neurology 260 (2013) 1332–1338.</li>

                    <br/>
                    <large>mPower</large>
                    <hr/>
                    <li>B. M. Bot, C. Suver, E. C. Neto, M. Kellen, A. Klein, C. Bare, M. Doerr,
                        A. Pratap, J. Wilbanks, E. R. Dorsey, et al., The mpower study,
                        parkinson disease mobile data collected using researchkit, Scientific data
                        3 (2016).
                    </li>
                    <br/>
                    <large>Speech Feature Extraction</large>
                    <hr/>
                    <li>M. Little, P. McSharry, I. Moroz, S. Roberts, Nonlinear, biophysicallyinformed speech pathology detection, in: Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on, volume 2, IEEE, pp. II–II</li>
                    <li>I. R. Titze, Nonlinear source–filter coupling in phonation: Theory a, The Journal of the Acoustical Society of America 123 (2008) 1902–1915.</li>
                    <li>A. Tsanas, M. A. Little, P. E. McSharry, L. O. Ramig, Accurate telemonitoring of parkinson’s disease progression by noninvasive speech tests, IEEE transactions on Biomedical Engineering</li>
                    <li>F. Eyben, Real-time speech and music classification by large audio feature space extraction, Springer, 2015.</li>
                    <li>F. Eyben, K. R. Scherer, B. W. Schuller, J. Sundberg, E. Andr´e, C. Busso, L. Y. Devillers, J. Epps, P. Laukka, S. S. Narayanan, et al., The geneva minimalistic acoustic parameter set (gemaps) for voice research and affective computing, IEEE Transactions on Affective Computing 7 (2016) 190–202.</li>
                    <li>F. Eyben, M. W¨ollmer, B. Schuller, Opensmile: the munich versatile and fast open-source audio feature extractor, in: Proceedings of the 18th ACM international conference on Multimedia, ACM, pp. 1459–1462.</li>
                    <br/>
                    <large>General Machine Learning</large>
                    <hr/>
                    <li>J. Li, K. Cheng, S. Wang, F. Morstatter, R. P. Trevino, J. Tang, H. Liu, Feature selection: A data perspective, arXiv preprint arXiv:1601.07996 (2016) </li>
                    <li>J. S. Bergstra, R. Bardenet, Y. Bengio, B. K´egl, Algorithms for hyperparameter
                    optimization, in: Advances in Neural Information Processing
                        Systems, pp. 2546–2554</li>

                    <li>K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: Surpassing
                    human-level performance on imagenet classification, in: Proceedings of
                        the IEEE international conference on computer vision, pp. 1026–1034.</li>
                    <li>F. Chollet, et al., Keras, 2015</li>
                    <li>T. Dozat, Incorporating nesterov momentum into adam (2016).</li>
                </ol>
                <br/><br/>
                <h2>Slide Material Sources</h2>
                <ul>
                    <li>http://www.healthline.com/hlcmsresource/images/topic_centers/neupro-parkinsons/
                        642x361_Parkinsons_Disease_Caregiving.jpg
                    </li>
                    <li>https://www.michaeljfox.org/files/foundation/1_2.2.jpg</li>
                    <li>https://www.sap.com/trends/machine-learning.html</li>
                    <li>https://www.crowdanalytix.com/api/assets/download?path=blogs/15/file.jpg</li>
                    <li>https://www.synapse.org/Portal/filehandle?ownerId=syn4993293&ownerType=ENTITY&xsrfToken=null&fileName=Screen Shot 2015-11-25 at 2.50.03 PM.png&preview=false&wikiId=247861</li>
                    <li>https://3.bp.blogspot.com/_UqlrkHvPijw/TJupAi2ztMI/AAAAAAAAAFI/6EVz1pmA1vs/s1600/svm.gif</li>
                    <li>http://farm5.static.flickr.com/4006/4608694916_1c6f17b2c6_o.png</li>
                    <li>http://cdn-ak.f.st-hatena.com/images/fotolife/T/TJO/20140106/20140106225602.png</li>
                    <li>https://www.filepicker.io/api/file/sZlixFY9RHKZRfjafMY5?policy=eyJoYW5kbGUiOiJzWmxpeEZZOVJIS1pSZmphZk1ZNSIsImV4cGlyeSI6MTUwMDYxNDA2NywiY2FsbCI6WyJyZWFkIl19&signature=279612e27a584b2472c2454c753d719a4202435930c7385a21fdfc73c134c4f0</li>
                    <li>https://www.researchgate.net/profile/Dirk_Van_den_Poel/publication/222834796/figure/fig2/AS:305107871780885@1449754793653/Figure-2-The-non-linear-boundary-in-the-input-space-is-mapped-via-a-kernel-function-into.png</li>
                </ul>
            </smaller>

        </section>
        <!--<section>-->
        <!--<section>-->
        <!--<h2>Fragment Styles</h2>-->
        <!--<p>There's different types of fragments, like:</p>-->
        <!--<p class="fragment grow">grow</p>-->
        <!--<p class="fragment shrink">shrink</p>-->
        <!--<p class="fragment fade-out">fade-out</p>-->
        <!--<p class="fragment fade-up">fade-up (also down, left and right!)</p>-->
        <!--<p class="fragment current-visible">current-visible</p>-->
        <!--<p>Highlight <span class="fragment highlight-red">red</span> <span-->
        <!--class="fragment highlight-blue">blue</span> <span class="fragment highlight-green">green</span>-->
        <!--</p>-->
        <!--</section>-->
        <!--</section>-->

        <!--<section>-->
        <!--<section data-background="#dddddd">-->
        <!--<h2>Slide Backgrounds</h2>-->
        <!--<p>-->
        <!--Set <code>data-background="#dddddd"</code> on a slide to change the background color. All CSS color-->
        <!--formats are supported.-->
        <!--</p>-->
        <!--<a href="#" class="navigate-down">-->
        <!--<img width="178" height="238" data-src="https://s3.amazonaws.com/hakim-static/reveal-js/arrow.png"-->
        <!--alt="Down arrow">-->
        <!--</a>-->
        <!--</section>-->
        <!--<section data-background="https://s3.amazonaws.com/hakim-static/reveal-js/image-placeholder.png">-->
        <!--<h2>Image Backgrounds</h2>-->
        <!--<pre><code class="hljs">&lt;section data-background="image.png"&gt;</code></pre>-->
        <!--</section>-->
        <!--<section data-background="https://s3.amazonaws.com/hakim-static/reveal-js/image-placeholder.png"-->
        <!--data-background-repeat="repeat" data-background-size="100px">-->
        <!--<h2>Tiled Backgrounds</h2>-->
        <!--<pre><code class="hljs" style="word-wrap: break-word;">&lt;section data-background="image.png" data-background-repeat="repeat" data-background-size="100px"&gt;</code></pre>-->
        <!--</section>-->
        <!--<section-->
        <!--data-background-video="https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.mp4,https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.webm"-->
        <!--data-background-color="#000000">-->
        <!--<div style="background-color: rgba(0, 0, 0, 0.9); color: #fff; padding: 20px;">-->
        <!--<h2>Video Backgrounds</h2>-->
        <!--<pre><code class="hljs" style="word-wrap: break-word;">&lt;section data-background-video="video.mp4,video.webm"&gt;</code></pre>-->
        <!--</div>-->
        <!--</section>-->
        <!--<section data-background="http://i.giphy.com/90F8aUepslB84.gif">-->
        <!--<h2>... and GIFs!</h2>-->
        <!--</section>-->
        <!--</section>-->

        <!--<section data-transition="slide" data-background="#4d7e65" data-background-transition="zoom">-->
        <!--<h2>Background Transitions</h2>-->
        <!--<p>-->
        <!--Different background transitions are available via the backgroundTransition option. This one's called-->
        <!--"zoom".-->
        <!--</p>-->
        <!--<pre><code class="hljs">Reveal.configure({ backgroundTransition: 'zoom' })</code></pre>-->
        <!--</section>-->

        <!--<section data-transition="slide" data-background="#b5533c" data-background-transition="zoom">-->
        <!--<h2>Background Transitions</h2>-->
        <!--<p>-->
        <!--You can override background transitions per-slide.-->
        <!--</p>-->
        <!--<pre><code class="hljs"-->
        <!--style="word-wrap: break-word;">&lt;section data-background-transition="zoom"&gt;</code></pre>-->
        <!--</section>-->
        <!--<section>-->

            <!--<h2>Pretty Code</h2>-->
            <!--<pre><code class="hljs" data-trim contenteditable>-->
<!--function linkify( selector ) {-->
  <!--if( supports3DTransforms ) {-->

    <!--var nodes = document.querySelectorAll( selector );-->

    <!--for( var i = 0, len = nodes.length; i &lt; len; i++ ) {-->
      <!--var node = nodes[i];-->

      <!--if( !node.className ) {-->
        <!--node.className += ' roll';-->
      <!--}-->
    <!--}-->
  <!--}-->
<!--}-->
					<!--</code></pre>-->
            <!--<p>Code syntax highlighting courtesy of <a href="http://softwaremaniacs.org/soft/highlight/en/description/">highlight.js</a>.-->
            <!--</p>-->
        <!--</section>-->

        <!--<section>-->
            <!--<h2>Speaker View</h2>-->
            <!--<p>There's a <a href="https://github.com/hakimel/reveal.js#speaker-notes">speaker view</a>. It includes a-->
                <!--timer, preview of the upcoming slide as well as your speaker notes.</p>-->
            <!--<p>Press the <em>S</em> key to try it out.</p>-->

            <!--<aside class="notes">-->
                <!--Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open-->
                <!--the speaker notes window (hit 's' on your keyboard).-->
            <!--</aside>-->
        <!--</section>-->

        <!--<section>-->
            <!--<h2>Export to PDF</h2>-->
            <!--<p>Presentations can be <a href="https://github.com/hakimel/reveal.js#pdf-export">exported to PDF</a>,-->
                <!--here's an example:</p>-->
            <!--<iframe data-src="https://www.slideshare.net/slideshow/embed_code/42840540" width="445" height="355"-->
                    <!--frameborder="0" marginwidth="0" marginheight="0" scrolling="no"-->
                    <!--style="border:3px solid #666; margin-bottom:5px; max-width: 100%;" allowfullscreen></iframe>-->
        <!--</section>-->


    </div>

</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>

    // More info https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: false,
        progress: true,
        history: true,
        center: true,
        keyboard: true,
        touch: true,
        fragments: true,
        hideAddressBar: true,
        previewLinks: false,
        transitionSpeed: 'fast', // default/fast/slow
        backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom
        viewDistance: 3,
        transition: 'fade', // none/fade/slide/convex/concave/zoom
        autoPlayMedia: true,

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
            {
                src: 'lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'plugin/highlight/highlight.js', async: true, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'plugin/zoom-js/zoom.js', async: true},
            {src: 'plugin/notes/notes.js', async: true},
        ]

    });

</script>

</body>
</html>
